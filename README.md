# hadoop command

- `ls`
    - `hdfs dfs -ls /`
    -  : hdfs dfs -ls <í™•ì¸í•˜ê³  ì‹¶ì€ ê²½ë¡œ> ìœ„ì— `/`ëŠ” ë£¨íŠ¸ í‘œì‹œ 

- `mkdir`
    - `hdfs dfs -mkdir /input`
    - : hdfs dfs -mkdir <ìƒì„±í•˜ê³  ì‹¶ì€ í´ë” ì´ë¦„>

- `put`
    - `hdfs dfs -put <ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ> <ì—…ë¡œë“œí•  ìœ„ì¹˜>`
    - : hdfs dfs -put ml-25m/movies.csv /input

- `cat`
    - `hdfs dfs -cat <ì¶œë ¥í•˜ê³ ì‹¶ì€ íŒŒì¼ ê²½ë¡œ >`
    - hdfs dfs -cat /input/movies.csv 
    - ë‚´ê°€ ì¶œë ¥í•˜ê³  ì‹¶ì€ ì „ì²´ ì½”ë“œ 

- `head`, `tail`
    - `hdfs dfs -head <ì¶œë ¥í•˜ê³  ì‹¶ì€ íŒŒì¼ ê²½ë¡œ>`
    - hdfs dfs -head /input/movies.csv
    - head (ì•ì— ë‚´ìš©), tail (ë’¤ì— ë‚´ìš©)

- `rm`
    - `hdfs dfs -rm <ì§€ìš¸ íŒŒì¼ ê²½ë¡œ>`
    - hdfs dfs -rm /ratings.csv
    - í´ë”ë¥¼ ì‚­ì œí•  ê²½ìš° -r ì˜µì…˜ ì¶”ê°€
    - `hdfs dfs -rm -r /input`


---

# 2025.04.08 
- windows/system32/drivers/etc/hosts(ë§¨ìœ„ì— íŒŒì¼)
    - ![alt text](img/image.png) ì—¬ê¸°ì„œ yerin. ê°€ì ¸ì˜¤ê¸° 
    - 127.0.0.1 yerin. vscodeë¡œ ì‹¤í–‰í•´ì„œ ì €ì¥í•˜ê¸°
    - ![alt text](img/image-1.png) 
    - ê·¸ëŸ¼ ì´ë ‡ê²Œ ë°ì´í„°ë¥¼ ë³¼ ìˆ˜ ìˆìŒ   
- í•˜ë‘¡ì€ ë°ì´í„°ë¥¼ ìˆ˜ì • í•  ìˆ˜ ì—†ìŒ (ì¶”ê°€ëŠ” ê°€ëŠ¥)

## ğŸ”¹MapReduceì˜ Mapê³¼ Reduce ê°œë… ì •ë¦¬
- Map ë‹¨ê³„

    - ë°ì´í„°ë¥¼ êº¼ë‚´ì„œ ê°€ê³µí•˜ëŠ” ì—­í• 

    - ì…ë ¥ ë°ì´í„°ë¥¼ í‚¤-ê°’(key-value) ìŒìœ¼ë¡œ ë³€í™˜í•¨

    - ë°ì´í„°ë¥¼ ë¶„í• í•˜ê³  í•„í„°ë§í•˜ëŠ” ë‹¨ê³„ë¡œ, ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨

    - ì˜ˆì‹œ:

        - í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë¥¼ êº¼ë‚´ê³  (ë‹¨ì–´, 1) í˜•íƒœë¡œ ë³€í™˜

- Reduce ë‹¨ê³„

    - Mapì—ì„œ ë‚˜ì˜¨ í‚¤-ê°’ ìŒì„ ê°™ì€ í‚¤ë¼ë¦¬ ëª¨ì•„ì„œ ì²˜ë¦¬í•¨

    - í•©ì‚°, í‰ê· , ì§‘ê³„, ì •ë ¬ ë“±ì˜ ë¡œì§ì„ ìˆ˜í–‰

    - ì˜ˆì‹œ:

        - (ë‹¨ì–´, [1, 1, 1, 1]) â†’ ë‹¨ì–´ì˜ ì´ ê°œìˆ˜: 4


- ![alt text](img/image-2.png)
    - `mapper.py`ì—ì„œ 
        - ```python
            # ë°ì´í„°ë¥¼ ìª¼ê°œëŠ” ì—­í• 
            import sys

            for line in sys.stdin: # text.txt íŒŒì¼ì„ ì „ë¶€ë‹¤ sys.stdinìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì„œ í•œì¤„ì”© lineì— ì €ì¥í•˜ê¸°
                line = line.strip() # ì¢Œìš° ê³µë°± ì—†ì• ê¸°
                words = line.split()
                # ['hi', 'good', 'sad']
    
                for word in words:
                 print(f'{word}\t1') #\t:í•œì¤„ì”© ë‚´ë ¤ì“°ê¸° 
            ```
    - `cat text.txt | python3 mapper.py`ë¡œ ì¶œë ¥í•´ë³´ë©´ ![alt text](img/image-3.png)
    - `reducer.py`ì—ì„œ
        - ```python
            import sys

            # hi      1
            # good    1
            # sad     1
            # home    1
            # ...
            # ìœ„ì— ë°ì´í„°ë“¤ì´ sys.stdinì— ë“¤ì–´ê°

            last_word = None # ê¸€ìê°€ ë°”ë€ŒëŠ” ì‹œì ì„ ì°¾ê¸° ìœ„í•´
            total_count = 0


            for line in sys.stdin:
                word, value = line.split() 
                value = int(value)
                
                if last_word == word:
                    total_count += value

                else:
                    if last_word is not None: # noneì´ ì•„ë‹ ë•Œ (ìµœì´ˆê°€ ì•„ë‹ë•Œ)
                        print(f'{last_word}\t{total_count}')
                    last_word = word
                    total_count = value # ìƒˆë¡œìš´ ë‹¨ì–´ê°€ ë“¤ì–´ì™”ìœ¼ë‹ˆê¹ 1ë¶€í„° ë‹¤ì‹œ ì‹œì‘
                    
            if last_word == word:
                print(f'{last_word}\t{total_count}')
            ```
- ![alt text](img/image-4.png)
- ![alt text](img/image-5.png)
- ì—¬ê¸°ì„œ í„°ë¯¸ë„ì— ëª…ë ¹ì–´ 
    - `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/text.txt \
 -output /output/wordcount \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/reducer.py'`ë¥¼ ì‹¤í–‰í•˜ë©´ `http://localhost:9870/explorer.html#/output/wordcount`ì—ì„œ![alt text](image-6.png) ì´ëŸ¬í•œ ê²°ê³¼ê°€ ë‚˜ì˜´

---
## hadoop version
- input : ë°ì´í„° ì–´ë””ì„œ ê°€ì ¸ì˜¬ê±´ì§€
- output : ë°ì´í„°ë¥¼ ì–´ë””ë‹¤ê°€ ì €ì¥í• ì§€
- mapper
- reducer
- ëª…ë ¹ì–´ ì‹¤í–‰í–‰
- `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/text.txt \
 -output /output/wordcount \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/reducer.py'`

 - chmod +x or chmod 755 rwx|rwx|rwx

---
# 1. ì˜í™”ì˜ í‰ì  í‰ê·  
- hdfs dfs -put ml-25m/input

- `/hadoop/1.movie-rate/avg/mapper.py`
    - ```python 
        import sys

        for line in sys.stdin:
            line = line.strip()
            
            fields = line.split(',') # ,ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°
            # ['1', '296', '5.0', '11133451414']
            
            movie_id = fields[1]
            rating = fields[2]
            
            
            print(f'{movie_id}\t{rating}')
        ```
- `/hadoop/1.movie-rate/avg/reducer.py`
    - ```python
        import sys


        currunt_movie_id = None
        currunt_sum = 0
        currunt_count = 0

        for line in sys.stdin:   
            line = line.strip() # ê³µë°±ì œê±°
            movie_id, rating = line.split() # movie_id, rating ë¶„ë¦¬
            
            try:
                rating = float(rating)
            except: # í‰ì ì´ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°ëŠ” ê±´ë„ˆëœ€
                continue # forë¬¸ì„ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ forë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° 
            
            # 123, 5.0 
            # 123, 3.5
            # 123, 4.0
            # 234, 4.2  ì˜í™”ì˜ ì½”ë“œ ìˆ«ìê°€ ë°”ë€”ë•Œê¹Œì§€ ì¶œë ¥í•˜ê¸° 
            
            if currunt_movie_id == movie_id:
                currunt_count += 1
                currunt_sum += rating
                
            else: # ì˜í™”ê°€ ë°”ë€Œì—ˆì„ ë–„
                if currunt_movie_id is not None:
                    currunt_avg = currunt_sum / currunt_count
                    print(f'{currunt_movie_id}\t{currunt_avg}')
                
                currunt_movie_id = movie_id
                currunt_count = 1
                currunt_sum = rating
            
        currunt_avg = currunt_sum / currunt_count
        print(f'{currunt_movie_id}\t{currunt_avg}') # ë§ˆì§€ë§‰ ì˜í™”ì˜ ê²°ê³¼ë„ ì¶œë ¥í•´ì•¼ í•˜ë¯€ë¡œ ì¶”ê°€ë¡œ í•œ ë²ˆ ë” ì²˜ë¦¬í•¨
        ```
- í„°ë¯¸ë„ì— ëª…ë ¹ì–´ ì‹¤í–‰
    - `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/ratings.csv \
 -output /output/movie-rate-avg \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/1.movie-rate-avg/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/1.movie-rate-avg/reducer.py'`
- http://localhost:9870/explorer.html#/output ì—ì„œ ![alt text](image-7.png) ì´ëŸ¬í•œ ê²°ê³¼ê°€ ë‚˜ì˜´ 
