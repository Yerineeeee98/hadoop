# hadoop command

- `ls`
    - `hdfs dfs -ls /`
    -  : hdfs dfs -ls <í™•ì¸í•˜ê³  ì‹¶ì€ ê²½ë¡œ> ìœ„ì— `/`ëŠ” ë£¨íŠ¸ í‘œì‹œ 

- `mkdir`
    - `hdfs dfs -mkdir /input`
    - : hdfs dfs -mkdir <ìƒì„±í•˜ê³  ì‹¶ì€ í´ë” ì´ë¦„>

- `put`
    - `hdfs dfs -put <ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ> <ì—…ë¡œë“œí•  ìœ„ì¹˜>`
    - : hdfs dfs -put ml-25m/movies.csv /input

- `cat`
    - `hdfs dfs -cat <ì¶œë ¥í•˜ê³ ì‹¶ì€ íŒŒì¼ ê²½ë¡œ >`
    - hdfs dfs -cat /input/movies.csv 
    - ë‚´ê°€ ì¶œë ¥í•˜ê³  ì‹¶ì€ ì „ì²´ ì½”ë“œ 

- `head`, `tail`
    - `hdfs dfs -head <ì¶œë ¥í•˜ê³  ì‹¶ì€ íŒŒì¼ ê²½ë¡œ>`
    - hdfs dfs -head /input/movies.csv
    - head (ì•ì— ë‚´ìš©), tail (ë’¤ì— ë‚´ìš©)

- `rm`
    - `hdfs dfs -rm <ì§€ìš¸ íŒŒì¼ ê²½ë¡œ>`
    - hdfs dfs -rm /ratings.csv
    - í´ë”ë¥¼ ì‚­ì œí•  ê²½ìš° -r ì˜µì…˜ ì¶”ê°€
    - `hdfs dfs -rm -r /input`


---

# 2025.04.08 
- windows/system32/drivers/etc/hosts(ë§¨ìœ„ì— íŒŒì¼)
    - ![alt text](img/image.png) ì—¬ê¸°ì„œ yerin. ê°€ì ¸ì˜¤ê¸° 
    - 127.0.0.1 yerin. vscodeë¡œ ì‹¤í–‰í•´ì„œ ì €ì¥í•˜ê¸°
    - ![alt text](img/image-1.png) 
    - ê·¸ëŸ¼ ì´ë ‡ê²Œ ë°ì´í„°ë¥¼ ë³¼ ìˆ˜ ìˆìŒ   
- í•˜ë‘¡ì€ ë°ì´í„°ë¥¼ ìˆ˜ì • í•  ìˆ˜ ì—†ìŒ (ì¶”ê°€ëŠ” ê°€ëŠ¥)

## ğŸ”¹MapReduceì˜ Mapê³¼ Reduce ê°œë… ì •ë¦¬
- Map ë‹¨ê³„

    - ë°ì´í„°ë¥¼ êº¼ë‚´ì„œ ê°€ê³µí•˜ëŠ” ì—­í• 

    - ì…ë ¥ ë°ì´í„°ë¥¼ í‚¤-ê°’(key-value) ìŒìœ¼ë¡œ ë³€í™˜í•¨

    - ë°ì´í„°ë¥¼ ë¶„í• í•˜ê³  í•„í„°ë§í•˜ëŠ” ë‹¨ê³„ë¡œ, ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨

    - ì˜ˆì‹œ:

        - í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë¥¼ êº¼ë‚´ê³  (ë‹¨ì–´, 1) í˜•íƒœë¡œ ë³€í™˜

- Reduce ë‹¨ê³„

    - Mapì—ì„œ ë‚˜ì˜¨ í‚¤-ê°’ ìŒì„ ê°™ì€ í‚¤ë¼ë¦¬ ëª¨ì•„ì„œ ì²˜ë¦¬í•¨

    - í•©ì‚°, í‰ê· , ì§‘ê³„, ì •ë ¬ ë“±ì˜ ë¡œì§ì„ ìˆ˜í–‰

    - ì˜ˆì‹œ:

        - (ë‹¨ì–´, [1, 1, 1, 1]) â†’ ë‹¨ì–´ì˜ ì´ ê°œìˆ˜: 4


- ![alt text](img/image-2.png)
    - `mapper.py`ì—ì„œ 
        - ```python
            # ë°ì´í„°ë¥¼ ìª¼ê°œëŠ” ì—­í• 
            import sys

            for line in sys.stdin: # text.txt íŒŒì¼ì„ ì „ë¶€ë‹¤ sys.stdinìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì„œ í•œì¤„ì”© lineì— ì €ì¥í•˜ê¸°
                line = line.strip() # ì¢Œìš° ê³µë°± ì—†ì• ê¸°
                words = line.split()
                # ['hi', 'good', 'sad']
    
                for word in words:
                 print(f'{word}\t1') #\t:í•œì¤„ì”© ë‚´ë ¤ì“°ê¸° 
            ```
    - `cat text.txt | python3 mapper.py`ë¡œ ì¶œë ¥í•´ë³´ë©´ ![alt text](img/image-3.png)
    - `reducer.py`ì—ì„œ
        - ```python
            import sys

            # hi      1
            # good    1
            # sad     1
            # home    1
            # ...
            # ìœ„ì— ë°ì´í„°ë“¤ì´ sys.stdinì— ë“¤ì–´ê°

            last_word = None # ê¸€ìê°€ ë°”ë€ŒëŠ” ì‹œì ì„ ì°¾ê¸° ìœ„í•´
            total_count = 0


            for line in sys.stdin:
                word, value = line.split() 
                value = int(value)
                
                if last_word == word:
                    total_count += value

                else:
                    if last_word is not None: # noneì´ ì•„ë‹ ë•Œ (ìµœì´ˆê°€ ì•„ë‹ë•Œ)
                        print(f'{last_word}\t{total_count}')
                    last_word = word
                    total_count = value # ìƒˆë¡œìš´ ë‹¨ì–´ê°€ ë“¤ì–´ì™”ìœ¼ë‹ˆê¹ 1ë¶€í„° ë‹¤ì‹œ ì‹œì‘
                    
            if last_word == word:
                print(f'{last_word}\t{total_count}')
            ```
- ![alt text](img/image-4.png)
- ![alt text](img/image-5.png)
- ì—¬ê¸°ì„œ í„°ë¯¸ë„ì— ëª…ë ¹ì–´ 
    - `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/text.txt \
 -output /output/wordcount \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/reducer.py'`ë¥¼ ì‹¤í–‰í•˜ë©´ `http://localhost:9870/explorer.html#/output/wordcount`ì—ì„œ![alt text](image-6.png) ì´ëŸ¬í•œ ê²°ê³¼ê°€ ë‚˜ì˜´

---
## hadoop version
- input : ë°ì´í„° ì–´ë””ì„œ ê°€ì ¸ì˜¬ê±´ì§€
- output : ë°ì´í„°ë¥¼ ì–´ë””ë‹¤ê°€ ì €ì¥í• ì§€
- mapper
- reducer
- ëª…ë ¹ì–´ ì‹¤í–‰í–‰
- `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/text.txt \
 -output /output/wordcount \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/0.wordcount/reducer.py'`

 - chmod +x or chmod 755 rwx|rwx|rwx

---
# 1. ì˜í™”ì˜ í‰ì  í‰ê·  
- hdfs dfs -put ml-25m/input

- `/hadoop/1.movie-rate/avg/mapper.py`
    - ```python 
        import sys

        for line in sys.stdin:
            line = line.strip()
            
            fields = line.split(',') # ,ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°
            # ['1', '296', '5.0', '11133451414']
            
            movie_id = fields[1]
            rating = fields[2]
            
            
            print(f'{movie_id}\t{rating}')
        ```
- `/hadoop/1.movie-rate/avg/reducer.py`
    - ```python
        import sys #sys.stdinì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ sys ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜´


        currunt_movie_id = None # í˜„ì¬ ì²˜ë¦¬ì¤‘ì¸ ì˜í™” ID NONEìœ¼ë¡œ ì´ˆê¸°í™”
        currunt_sum = 0 # ì´ í‰ì 
        currunt_count = 0 # í‰ì  ê°œìˆ˜

        for line in sys.stdin:   
            line = line.strip() # ê³µë°±ì œê±°
            # ì¤„ ëì˜ ê³µë°± ë¬¸ì(ê°œí–‰ í¬í•¨) ë¥¼ ì œê±°

            # ì˜ˆ: "123 5.0\n" â†’ "123 5.0"
            movie_id, rating = line.split() # ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ìì—´ì„ ë¶„ë¦¬í•´ì„œ movie_id, rating ë³€ìˆ˜ì— ê°ê° ì €ì¥ì¥
            
            try:
                rating = float(rating)
                # í‰ì  ê°’ì„ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„ 
            except: # í‰ì ì´ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°ëŠ” ê±´ë„ˆëœ€(ì—ëŸ¬ê°€ ë‚˜ë©´)
                continue # forë¬¸ì„ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ forë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° 
            
            # 123, 5.0 
            # 123, 3.5
            # 123, 4.0
            # 234, 4.2  ì˜í™”ì˜ ì½”ë“œ ìˆ«ìê°€ ë°”ë€”ë•Œê¹Œì§€ ì¶œë ¥í•˜ê¸° 
            
            if currunt_movie_id == movie_id:
                # ê°™ì€ ì˜í™”ë¼ë©´ 
                currunt_count += 1 # í‰ì  ê°œìˆ˜ ì¦ê°€
                currunt_sum += rating # í‰ì  í•©ê³„ë„ ì¶”ê°€ê°€
                
            else: # ì˜í™”ê°€ ë°”ë€Œì—ˆì„ ë–„
                if currunt_movie_id is not None:
                    # ì²˜ìŒì´ ì•„ë‹ˆë¼ë©´ ( ì´ë¯¸ í•˜ë‚˜ ì´ìƒ ì˜í™”ê°€ ì²˜ë¦¬ëœ ìƒíƒœë¼ë©´ë©´)
                    currunt_avg = currunt_sum / currunt_count # ì´ì „ ì˜í™”ì˜ í‰ê·  í‰ì ì„ ê³„ì‚°í•´ì„œ ì¶œë ¥í•¨í•¨
                    print(f'{currunt_movie_id}\t{currunt_avg}')
                
                # í˜„ì¬ ì˜í™” id ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ì´ˆê¸°í™”
                # ì´ì œë¶€í„° ì´ ì˜í™”ì˜ í‰ì ì„ ìƒˆë¡œ ëª¨ìœ¼ê¸° ì‹œì‘í•¨
                currunt_movie_id = movie_id
                currunt_count = 1
                currunt_sum = rating
            
        currunt_avg = currunt_sum / currunt_count
        print(f'{currunt_movie_id}\t{currunt_avg}') #  ë£¨í”„ê°€ ëë‚œ í›„, ë§ˆì§€ë§‰ ì˜í™”ì˜ í‰ê· ì„ ë§ˆì§€ë§‰ìœ¼ë¡œ ì¶œë ¥í•¨
        #(ë£¨í”„ ì•ˆì—ì„œëŠ” ì˜í™” IDê°€ ë°”ë€” ë•Œë§Œ ì¶œë ¥í•˜ê¸° ë•Œë¬¸ì—, ë§ˆì§€ë§‰ ì˜í™”ëŠ” ë”°ë¡œ ì²˜ë¦¬ í•„ìš”!)
        ```
- í„°ë¯¸ë„ì— ëª…ë ¹ì–´ ì‹¤í–‰
    - `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/ratings.csv \
 -output /output/movie-rate-avg \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/1.movie-rate-avg/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/1.movie-rate-avg/reducer.py'`
- http://localhost:9870/explorer.html#/output ì—ì„œ ![alt text](image-7.png) ì´ëŸ¬í•œ ê²°ê³¼ê°€ ë‚˜ì˜´ 

# 2. log-time 
- ë¡œê·¸ì¸ ì ‘ì†í•œ ì‚¬ëŒ ì‹œê°„
- hdfs dfs -put access.log/input
- `hadoop/2.log-time/mapper.py`
    - ```python
        import sys
        import re # ì •ê·œí‘œí˜„ì‹

        # 54.36.149.41 - - [22/Jan/2019:03:56:14 +0330] "GET /filter/27|13%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,27|%DA%A9%D9%85%D8%AA%D8%B1%20%D8%A7%D8%B2%205%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C%DA%A9%D8%B3%D9%84,p53 HTTP/1.1" 200 30577 "-" "Mozilla/5.0 (compatible; AhrefsBot/6.1; +http://ahrefs.com/robot/)" "-"
        # ìœ„ì—ëŠ” ì‹¤ì œ ë¡œê·¸ í•œ ì¤„ì˜ ì˜ˆì‹œ
        # :03:56:14
        time_pattern = re.compile(r':(\d{2}):(\d{2}):(\d{2})')
        # (r ë’¤ì— ìˆëŠ” ë¬¸ìëŠ” ì •ê·œí‘œí˜„ì‹ì´ë¼ëŠ” ì˜ë¯¸) :\d{2}ì–´ë–¤ ìˆ«ìë“  2ìë¦¬ ìˆ«ìì´ë©´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì˜ë¯¸
        # :(\d{2}):(\d{2}):(\d{2}) â†’ ì˜ˆ: :03:56:14

            #ì²« ë²ˆì§¸ \d{2}: ì‹œ(hour)

            #ë‘ ë²ˆì§¸ \d{2}: ë¶„(minute)

            #ì„¸ ë²ˆì§¸ \d{2}: ì´ˆ(second)
        # ì´ ì •ê·œí‘œí˜„ì‹ì€ :03:56:14ì—ì„œ ìˆ«ìë§Œ ë½‘ê¸° ìœ„í•´ ë§Œë“  ê²ƒ
        for line in sys.stdin:
            line = line.strip()
            # ì¤„ ëì— ìˆëŠ” ì¤„ë°”ê¿ˆ ë¬¸ì(\n)ë‚˜ ê³µë°±ì„ ì œê±°

            match = time_pattern.search(line)
            # ì•„ê¹Œ ë§Œë“  ì •ê·œí‘œí˜„ì‹ time_patternì„ ì´ìš©í•´ì„œ
            # í˜„ì¬ ì¤„(line)ì—ì„œ ì‹œê°„ ì •ë³´ë¥¼ ì°¾ëŠ” ë¶€ë¶„
            if match: # matchê°€ Noneì´ ì•„ë‹ˆë©´ 
                hour = match.group(1)
                print(f'{hour}\t1')
                # (r':(\d{2}:\d{2}:\d{2})') ì—¬ê¸°ì„œ ì†Œê´„í˜¸ë¡œ ë¬¶ì€ê²ƒì¤‘ ì²«ë²ˆì¨° 0ë²ˆì§¸ê°€ ì•„ë‹Œ 1ë²ˆì§¸ì¸ ì´ìœ ëŠ” 0ë²ˆì§¸ëŠ” ì†Œê´„í˜¸ ê·¸ìì²´ë¥¼ ì˜ë¯¸
    - `hadoop/2.log-time/reducer.py`
        - ```python     
            import sys

            last_hour = None # ì´ì „ ì¤„ì˜ ì‹œê°„ ì •ë³´ ì €ì¥ìš©ìš©
            total_count = 0 # í˜„ì¬ ì‹œê°„ëŒ€ì— ëŒ€í•œ ì´ ìš”ì²­ ìˆ˜ ì €ì¥ìš©

            # 03    1
            # 03    1
            # 04    1
            # 05    1 # mapperê°€ ì¶œë ¥í•œ ì˜ˆì‹œ


            for line in sys.stdin: # hadoopì´ mapper -> reducerë¡œ ë„˜ê¸´ ë°ì´í„°ë¥¼ í•œ ì¤„ì”© ì½ëŠ” ë°˜ë³µë¬¸
                line = line.strip()

                hour, value = line.split() # íƒ­ì´ë‚˜ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œê°„ê³¼(hour)ê³¼ ê°œìˆ˜(value)ë¶„ë¦¬
                value = int(value) 

                if last_hour == hour: # ê°™ì€ ì‹œê°„ëŒ€ë‹ˆê¹ valueë¥¼ ëˆ„ì 
                    total_count += value
                else: # ë‹¤ë¥¸ ì‹œê°„ëŒ€ë¡œ ë°”ë€Œë©´ -> ì§€ê¸ˆê¹Œì§€ ëˆ„ì í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  
                    if last_hour is not None:
                        print(f'{last_hour}\t{total_count}')
                    
                    last_hour = hour # í˜„ì¬ ì‹œê°„ëŒ€ë¥¼ ë°”ê¾¸ê³  ìƒˆë¡œìš´ ì‹œê°„ëŒ€ì— ëŒ€í•œ ì¹´ìš´íŠ¸ ì‹œì‘
                    total_count = value

            print(f'{last_hour}\t{total_count}') # ë§ˆì§€ë§‰ ì¤„ì€ forë¬¸ì´ ëë‚˜ê³  ë‚˜ì„œ ë”°ë¡œ ë˜ í•œë²ˆ ë” ì¶œë ¥í•´ì£¼ê¸° 
            ```
- `hadoop jar ~/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\
 -input /input/access.log \
 -output /output/log-time \
 -mapper 'python3 /home/ubuntu/damf2/hadoop/2.log-time/mapper.py' \
 -reducer 'python3 /home/ubuntu/damf2/hadoop/2.log-time/reducer.py'` í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•´ì£¼ê¸°

- http://localhost:9870/explorer.html#/output/log-time ![alt text](image.png) 
    


